{"cells":[{"cell_type":"code","source":[""],"metadata":{"id":"5tXyHf-eRuqj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21597,"status":"ok","timestamp":1653466198342,"user":{"displayName":"Fer Vincent","userId":"04845778604314705618"},"user_tz":-120},"id":"qi8oC_K4iBzY","outputId":"0ae9c047-852b-44c1-a076-9c4e5d72e145"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19300,"status":"ok","timestamp":1653466217637,"user":{"displayName":"Fer Vincent","userId":"04845778604314705618"},"user_tz":-120},"id":"FpvUOuC3j27n","outputId":"1f76d2a6-6821-4856-db5e-df8e9d7df5cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensorflow version 2.8.0\n","INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.67.45.82:8470\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.67.45.82:8470\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"name":"stdout","output_type":"stream","text":["All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n","INFO:tensorflow:Found TPU system:\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]}],"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","import os\n","print(\"Tensorflow version \" + tf.__version__)\n","\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","\n","# This is the TPU initialization code that has to be at the beginning.\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n","\n","strategy = tf.distribute.TPUStrategy(resolver)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36t6DMrDPjT8"},"outputs":[],"source":["import numpy as np\n","import keras\n","import time\n","import tensorflow as tf\n","from keras.callbacks import ModelCheckpoint, EarlyStopping,Callback\n","from keras.layers import Dense,Reshape,Input,BatchNormalization,Dropout,concatenate,Flatten,Lambda,Resizing,CuDNNLSTM,concatenate,Layer,LSTM,Conv2D,MaxPool2D\n","from keras import  Model,layers\n","from tensorflow.keras.applications import VGG16\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rn-NFo6ZPorz"},"outputs":[],"source":["def find_removable(n,batch_size=64):\n","      return n%batch_size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6207,"status":"ok","timestamp":1653466224056,"user":{"displayName":"Fer Vincent","userId":"04845778604314705618"},"user_tz":-120},"id":"r8qWJIpgQNnm","outputId":"a7f14915-417c-4305-f5be-c08a07ee3d47"},"outputs":[{"name":"stdout","output_type":"stream","text":["lost 31\n"]}],"source":["base_path = '/content/drive/MyDrive/Colab Notebooks/OAD/OAD/Vincent/NEW/oad_fusion_2img/40/'\n","# base_path = '/content/drive/MyDrive/Colab Notebooks/NTU/Vincent/ntu_3cam/'\n","input_shape= (50,40,3)\n","\n","train_x = np.load(base_path+'train_x.npy')\n","test_x = np.load(base_path+'test_x.npy')\n","train_y = np.load(base_path+'train_y.npy')\n","test_y = np.load(base_path+'test_y.npy')\n","val_x = test_x\n","val_y = test_y\n","np.random.seed(11)\n","np.random.shuffle(val_x)\n","np.random.seed(11)\n","np.random.shuffle(val_y)\n","val_x = val_x[:1000]\n","val_y = val_y[:1000]\n","\n","batch_size=32\n","\n","n = find_removable(len(train_x),batch_size)\n","train_x = train_x[:-n]\n","train_y = train_y[:-n]\n","\n","print('lost',n)\n","\n","train = (train_x,train_y)\n","test = (test_x,test_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1329,"status":"ok","timestamp":1653476566034,"user":{"displayName":"Fer Vincent","userId":"04845778604314705618"},"user_tz":-120},"id":"jxmCPupJ_WSc","outputId":"46fbde06-b292-4428-dda6-0afcdebc4e32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 50, 40, 3)]       0         \n","                                                                 \n"," conv2d_68 (Conv2D)          (None, 50, 40, 16)        448       \n","                                                                 \n"," max_pooling2d_37 (MaxPoolin  (None, 25, 20, 16)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_69 (Conv2D)          (None, 25, 20, 32)        4640      \n","                                                                 \n"," max_pooling2d_38 (MaxPoolin  (None, 12, 10, 32)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_70 (Conv2D)          (None, 12, 10, 64)        8256      \n","                                                                 \n"," conv2d_71 (Conv2D)          (None, 12, 10, 64)        16448     \n","                                                                 \n"," max_pooling2d_39 (MaxPoolin  (None, 6, 5, 64)         0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_72 (Conv2D)          (None, 6, 5, 128)         32896     \n","                                                                 \n"," conv2d_73 (Conv2D)          (None, 6, 5, 128)         65664     \n","                                                                 \n"," conv2d_74 (Conv2D)          (None, 6, 5, 128)         65664     \n","                                                                 \n"," max_pooling2d_40 (MaxPoolin  (None, 3, 2, 128)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_75 (Conv2D)          (None, 3, 2, 256)         131328    \n","                                                                 \n"," conv2d_76 (Conv2D)          (None, 3, 2, 256)         262400    \n","                                                                 \n"," conv2d_77 (Conv2D)          (None, 3, 2, 256)         262400    \n","                                                                 \n"," max_pooling2d_41 (MaxPoolin  (None, 1, 1, 256)        0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_5 (Flatten)         (None, 256)               0         \n","                                                                 \n"," dense_10 (Dense)            (None, 256)               65792     \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 256)              1024      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_11 (Dense)            (None, 10)                2570      \n","                                                                 \n","=================================================================\n","Total params: 919,530\n","Trainable params: 919,018\n","Non-trainable params: 512\n","_________________________________________________________________\n"]}],"source":["with strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n","  inp=Input(np.asarray(input_shape))\n","  output = Conv2D(16,padding='same',activation='relu',kernel_size=(3,3))(inp)\n","  output = MaxPool2D(pool_size=(2,2),strides=2)(output)\n","  output = Conv2D(32,padding='same',activation='relu',kernel_size=(3,3))(output)\n","  output = MaxPool2D(pool_size=(2,2),strides=2)(output)\n","  output = Conv2D(64,padding='same',activation='relu',kernel_size=(2,2))(output)\n","  output = Conv2D(64,padding='same',activation='relu',kernel_size=(2,2))(output)\n","  output = MaxPool2D(pool_size=(2,2),strides=2)(output)\n","  output = Conv2D(128,padding='same',activation='relu',kernel_size=(2,2))(output)\n","  output = Conv2D(128,padding='same',activation='relu',kernel_size=(2,2))(output)\n","  output = Conv2D(128,padding='same',activation='relu',kernel_size=(2,2))(output)\n","  output = MaxPool2D(pool_size=(2,2),strides=2)(output)\n","  output = Conv2D(256,padding='same',activation='relu',kernel_size=(2,2))(output)\n","  output = Conv2D(256,padding='same',activation='relu',kernel_size=(2,2))(output)\n","  output = Conv2D(256,padding='same',activation='relu',kernel_size=(2,2))(output)\n","  output = MaxPool2D(pool_size=(2,2),strides=2)(output)\n","  output = Flatten()(output)\n","  output = Dense(256,activation='relu',kernel_regularizer='l1')(output)\n","  output = BatchNormalization()(output)\n","  output = Dense(10, activation='softmax',kernel_regularizer='l1')(output)\n","  model = Model(inp, output)\n","  model.summary()\n","  optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n","  model.compile(loss=keras.losses.categorical_crossentropy,\n","                optimizer=optimizer,\n","                metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOGIAZxigOcH","executionInfo":{"status":"ok","timestamp":1653478222284,"user_tz":-120,"elapsed":1654801,"user":{"displayName":"Fer Vincent","userId":"04845778604314705618"}},"outputId":"c6704b26-3f6c-4a9b-a3c0-fd2918e567e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","372/372 [==============================] - 13s 26ms/step - loss: 37.0519 - accuracy: 0.7047 - val_loss: 35.9678 - val_accuracy: 0.6240\n","Epoch 2/300\n","372/372 [==============================] - 6s 16ms/step - loss: 34.1692 - accuracy: 0.8510 - val_loss: 33.2653 - val_accuracy: 0.7470\n","Epoch 3/300\n","372/372 [==============================] - 6s 16ms/step - loss: 31.6938 - accuracy: 0.8905 - val_loss: 30.9112 - val_accuracy: 0.7630\n","Epoch 4/300\n","372/372 [==============================] - 6s 16ms/step - loss: 29.3503 - accuracy: 0.9151 - val_loss: 28.5492 - val_accuracy: 0.8200\n","Epoch 5/300\n","372/372 [==============================] - 6s 16ms/step - loss: 27.1233 - accuracy: 0.9328 - val_loss: 26.3261 - val_accuracy: 0.8350\n","Epoch 6/300\n","372/372 [==============================] - 6s 17ms/step - loss: 24.9925 - accuracy: 0.9455 - val_loss: 24.2681 - val_accuracy: 0.8470\n","Epoch 7/300\n","372/372 [==============================] - 6s 16ms/step - loss: 22.9718 - accuracy: 0.9536 - val_loss: 22.2103 - val_accuracy: 0.8690\n","Epoch 8/300\n","372/372 [==============================] - 6s 16ms/step - loss: 21.0354 - accuracy: 0.9560 - val_loss: 20.7798 - val_accuracy: 0.7400\n","Epoch 9/300\n","372/372 [==============================] - 6s 16ms/step - loss: 19.1990 - accuracy: 0.9593 - val_loss: 18.6668 - val_accuracy: 0.8410\n","Epoch 10/300\n","372/372 [==============================] - 6s 17ms/step - loss: 17.4438 - accuracy: 0.9672 - val_loss: 16.8655 - val_accuracy: 0.8640\n","Epoch 11/300\n","372/372 [==============================] - 6s 17ms/step - loss: 15.7856 - accuracy: 0.9682 - val_loss: 15.2456 - val_accuracy: 0.8780\n","Epoch 12/300\n","372/372 [==============================] - 6s 17ms/step - loss: 14.2183 - accuracy: 0.9745 - val_loss: 13.6600 - val_accuracy: 0.8890\n","Epoch 13/300\n","372/372 [==============================] - 6s 16ms/step - loss: 12.7405 - accuracy: 0.9728 - val_loss: 12.4934 - val_accuracy: 0.8090\n","Epoch 14/300\n","372/372 [==============================] - 6s 16ms/step - loss: 11.3486 - accuracy: 0.9742 - val_loss: 10.9206 - val_accuracy: 0.8850\n","Epoch 15/300\n","372/372 [==============================] - 6s 16ms/step - loss: 10.0276 - accuracy: 0.9809 - val_loss: 9.6562 - val_accuracy: 0.8780\n","Epoch 16/300\n","372/372 [==============================] - 6s 16ms/step - loss: 8.8211 - accuracy: 0.9778 - val_loss: 8.4697 - val_accuracy: 0.8740\n","Epoch 17/300\n","372/372 [==============================] - 6s 16ms/step - loss: 7.6890 - accuracy: 0.9773 - val_loss: 7.3758 - val_accuracy: 0.8810\n","Epoch 18/300\n","372/372 [==============================] - 6s 16ms/step - loss: 6.6372 - accuracy: 0.9812 - val_loss: 6.3760 - val_accuracy: 0.8870\n","Epoch 19/300\n","372/372 [==============================] - 6s 16ms/step - loss: 5.6945 - accuracy: 0.9761 - val_loss: 5.4487 - val_accuracy: 0.8830\n","Epoch 20/300\n","372/372 [==============================] - 6s 16ms/step - loss: 4.8106 - accuracy: 0.9819 - val_loss: 4.6097 - val_accuracy: 0.8860\n","Epoch 21/300\n","372/372 [==============================] - 6s 16ms/step - loss: 4.0288 - accuracy: 0.9800 - val_loss: 3.8547 - val_accuracy: 0.8840\n","Epoch 22/300\n","372/372 [==============================] - 6s 16ms/step - loss: 3.3314 - accuracy: 0.9808 - val_loss: 3.2130 - val_accuracy: 0.8780\n","Epoch 23/300\n","372/372 [==============================] - 6s 17ms/step - loss: 2.7142 - accuracy: 0.9818 - val_loss: 2.6185 - val_accuracy: 0.8940\n","Epoch 24/300\n","372/372 [==============================] - 7s 18ms/step - loss: 2.1957 - accuracy: 0.9814 - val_loss: 2.1610 - val_accuracy: 0.8820\n","Epoch 25/300\n","372/372 [==============================] - 6s 16ms/step - loss: 1.7581 - accuracy: 0.9818 - val_loss: 1.7722 - val_accuracy: 0.8830\n","Epoch 26/300\n","372/372 [==============================] - 6s 16ms/step - loss: 1.4154 - accuracy: 0.9818 - val_loss: 1.4981 - val_accuracy: 0.8770\n","Epoch 27/300\n","372/372 [==============================] - 6s 16ms/step - loss: 1.1615 - accuracy: 0.9776 - val_loss: 1.2681 - val_accuracy: 0.8810\n","Epoch 28/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.9801 - accuracy: 0.9790 - val_loss: 1.1591 - val_accuracy: 0.8590\n","Epoch 29/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.8681 - accuracy: 0.9815 - val_loss: 1.0660 - val_accuracy: 0.8810\n","Epoch 30/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.8259 - accuracy: 0.9799 - val_loss: 1.0007 - val_accuracy: 0.8790\n","Epoch 31/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.7954 - accuracy: 0.9772 - val_loss: 0.9495 - val_accuracy: 0.8900\n","Epoch 32/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.7599 - accuracy: 0.9816 - val_loss: 0.9316 - val_accuracy: 0.8850\n","Epoch 33/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.7467 - accuracy: 0.9798 - val_loss: 1.0180 - val_accuracy: 0.8640\n","Epoch 34/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.7296 - accuracy: 0.9805 - val_loss: 0.9037 - val_accuracy: 0.8840\n","Epoch 35/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.7155 - accuracy: 0.9805 - val_loss: 0.8827 - val_accuracy: 0.8920\n","Epoch 36/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.7055 - accuracy: 0.9793 - val_loss: 0.9011 - val_accuracy: 0.8820\n","Epoch 37/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.6955 - accuracy: 0.9802 - val_loss: 0.9538 - val_accuracy: 0.8790\n","Epoch 38/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6803 - accuracy: 0.9826 - val_loss: 0.9620 - val_accuracy: 0.8650\n","Epoch 39/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6698 - accuracy: 0.9833 - val_loss: 0.8743 - val_accuracy: 0.8870\n","Epoch 40/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6649 - accuracy: 0.9820 - val_loss: 0.8651 - val_accuracy: 0.8870\n","Epoch 41/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6506 - accuracy: 0.9848 - val_loss: 0.8863 - val_accuracy: 0.8770\n","Epoch 42/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6441 - accuracy: 0.9859 - val_loss: 0.8162 - val_accuracy: 0.8980\n","Epoch 43/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6426 - accuracy: 0.9845 - val_loss: 0.8220 - val_accuracy: 0.8900\n","Epoch 44/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6362 - accuracy: 0.9861 - val_loss: 0.8217 - val_accuracy: 0.8940\n","Epoch 45/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6260 - accuracy: 0.9856 - val_loss: 0.8228 - val_accuracy: 0.8940\n","Epoch 46/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6224 - accuracy: 0.9871 - val_loss: 0.8258 - val_accuracy: 0.8910\n","Epoch 47/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6189 - accuracy: 0.9857 - val_loss: 0.8896 - val_accuracy: 0.8810\n","Epoch 48/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6142 - accuracy: 0.9870 - val_loss: 0.8166 - val_accuracy: 0.8920\n","Epoch 49/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6054 - accuracy: 0.9885 - val_loss: 0.7989 - val_accuracy: 0.8950\n","Epoch 50/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6120 - accuracy: 0.9868 - val_loss: 0.8340 - val_accuracy: 0.8830\n","Epoch 51/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.6044 - accuracy: 0.9866 - val_loss: 0.8723 - val_accuracy: 0.8800\n","Epoch 52/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5995 - accuracy: 0.9881 - val_loss: 0.8437 - val_accuracy: 0.8770\n","Epoch 53/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5984 - accuracy: 0.9873 - val_loss: 0.9629 - val_accuracy: 0.8600\n","Epoch 54/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5956 - accuracy: 0.9872 - val_loss: 0.8300 - val_accuracy: 0.8860\n","Epoch 55/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5893 - accuracy: 0.9864 - val_loss: 0.8010 - val_accuracy: 0.8940\n","Epoch 56/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5790 - accuracy: 0.9913 - val_loss: 0.8257 - val_accuracy: 0.8900\n","Epoch 57/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5848 - accuracy: 0.9885 - val_loss: 0.8050 - val_accuracy: 0.8930\n","Epoch 58/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5788 - accuracy: 0.9892 - val_loss: 0.8339 - val_accuracy: 0.8770\n","Epoch 59/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5808 - accuracy: 0.9888 - val_loss: 0.7800 - val_accuracy: 0.8930\n","Epoch 60/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5736 - accuracy: 0.9906 - val_loss: 0.7873 - val_accuracy: 0.8940\n","Epoch 61/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5777 - accuracy: 0.9886 - val_loss: 0.7679 - val_accuracy: 0.8950\n","Epoch 62/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5648 - accuracy: 0.9916 - val_loss: 0.8547 - val_accuracy: 0.8730\n","Epoch 63/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5635 - accuracy: 0.9902 - val_loss: 0.8169 - val_accuracy: 0.8950\n","Epoch 64/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.5601 - accuracy: 0.9903 - val_loss: 0.8826 - val_accuracy: 0.8760\n","Epoch 65/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5604 - accuracy: 0.9917 - val_loss: 0.8061 - val_accuracy: 0.8900\n","Epoch 66/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5544 - accuracy: 0.9910 - val_loss: 0.7734 - val_accuracy: 0.8980\n","Epoch 67/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5633 - accuracy: 0.9898 - val_loss: 0.7847 - val_accuracy: 0.9040\n","Epoch 68/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5517 - accuracy: 0.9907 - val_loss: 0.9232 - val_accuracy: 0.8760\n","Epoch 69/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5601 - accuracy: 0.9896 - val_loss: 0.7997 - val_accuracy: 0.8940\n","Epoch 70/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5442 - accuracy: 0.9921 - val_loss: 0.8094 - val_accuracy: 0.8890\n","Epoch 71/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5589 - accuracy: 0.9901 - val_loss: 0.8095 - val_accuracy: 0.8890\n","Epoch 72/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5420 - accuracy: 0.9929 - val_loss: 0.9584 - val_accuracy: 0.8530\n","Epoch 73/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5517 - accuracy: 0.9907 - val_loss: 2.2308 - val_accuracy: 0.6110\n","Epoch 74/300\n","372/372 [==============================] - 7s 18ms/step - loss: 0.5334 - accuracy: 0.9936 - val_loss: 0.7747 - val_accuracy: 0.9060\n","Epoch 75/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.5266 - accuracy: 0.9934 - val_loss: 0.8306 - val_accuracy: 0.8910\n","Epoch 76/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5380 - accuracy: 0.9926 - val_loss: 0.7841 - val_accuracy: 0.9020\n","Epoch 77/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5364 - accuracy: 0.9921 - val_loss: 0.8058 - val_accuracy: 0.8900\n","Epoch 78/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5360 - accuracy: 0.9930 - val_loss: 0.7654 - val_accuracy: 0.8950\n","Epoch 79/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5306 - accuracy: 0.9930 - val_loss: 0.7627 - val_accuracy: 0.8940\n","Epoch 80/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5309 - accuracy: 0.9924 - val_loss: 0.7974 - val_accuracy: 0.8970\n","Epoch 81/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5255 - accuracy: 0.9933 - val_loss: 0.7803 - val_accuracy: 0.9010\n","Epoch 82/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5209 - accuracy: 0.9944 - val_loss: 0.8111 - val_accuracy: 0.8980\n","Epoch 83/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5251 - accuracy: 0.9936 - val_loss: 0.8211 - val_accuracy: 0.8820\n","Epoch 84/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5234 - accuracy: 0.9935 - val_loss: 0.8350 - val_accuracy: 0.8910\n","Epoch 85/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5227 - accuracy: 0.9939 - val_loss: 0.8220 - val_accuracy: 0.8950\n","Epoch 86/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5224 - accuracy: 0.9928 - val_loss: 0.7901 - val_accuracy: 0.8940\n","Epoch 87/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5107 - accuracy: 0.9946 - val_loss: 0.8537 - val_accuracy: 0.8880\n","Epoch 88/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5134 - accuracy: 0.9946 - val_loss: 0.7736 - val_accuracy: 0.8970\n","Epoch 89/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5188 - accuracy: 0.9934 - val_loss: 0.8214 - val_accuracy: 0.8970\n","Epoch 90/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5126 - accuracy: 0.9946 - val_loss: 0.7616 - val_accuracy: 0.8930\n","Epoch 91/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5152 - accuracy: 0.9952 - val_loss: 0.7638 - val_accuracy: 0.8970\n","Epoch 92/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5103 - accuracy: 0.9949 - val_loss: 0.7724 - val_accuracy: 0.8950\n","Epoch 93/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5179 - accuracy: 0.9947 - val_loss: 0.8217 - val_accuracy: 0.8950\n","Epoch 94/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5174 - accuracy: 0.9940 - val_loss: 0.8413 - val_accuracy: 0.8900\n","Epoch 95/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5206 - accuracy: 0.9934 - val_loss: 0.7873 - val_accuracy: 0.8970\n","Epoch 96/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5067 - accuracy: 0.9939 - val_loss: 0.7979 - val_accuracy: 0.8970\n","Epoch 97/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5105 - accuracy: 0.9952 - val_loss: 0.7568 - val_accuracy: 0.9040\n","Epoch 98/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5023 - accuracy: 0.9945 - val_loss: 0.8495 - val_accuracy: 0.8760\n","Epoch 99/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4957 - accuracy: 0.9956 - val_loss: 0.7758 - val_accuracy: 0.9010\n","Epoch 100/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5069 - accuracy: 0.9936 - val_loss: 0.7827 - val_accuracy: 0.8900\n","Epoch 101/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5004 - accuracy: 0.9947 - val_loss: 0.7886 - val_accuracy: 0.8990\n","Epoch 102/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5054 - accuracy: 0.9955 - val_loss: 0.9147 - val_accuracy: 0.8790\n","Epoch 103/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5088 - accuracy: 0.9950 - val_loss: 0.7881 - val_accuracy: 0.9000\n","Epoch 104/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5131 - accuracy: 0.9934 - val_loss: 0.7759 - val_accuracy: 0.8970\n","Epoch 105/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5002 - accuracy: 0.9956 - val_loss: 0.7805 - val_accuracy: 0.9010\n","Epoch 106/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5075 - accuracy: 0.9937 - val_loss: 0.7804 - val_accuracy: 0.8910\n","Epoch 107/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5059 - accuracy: 0.9945 - val_loss: 0.8143 - val_accuracy: 0.8810\n","Epoch 108/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4964 - accuracy: 0.9964 - val_loss: 0.8312 - val_accuracy: 0.8960\n","Epoch 109/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.5000 - accuracy: 0.9954 - val_loss: 0.7845 - val_accuracy: 0.9010\n","Epoch 110/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5004 - accuracy: 0.9940 - val_loss: 0.8062 - val_accuracy: 0.8940\n","Epoch 111/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5066 - accuracy: 0.9937 - val_loss: 0.7871 - val_accuracy: 0.8980\n","Epoch 112/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5022 - accuracy: 0.9954 - val_loss: 0.8021 - val_accuracy: 0.8920\n","Epoch 113/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4952 - accuracy: 0.9955 - val_loss: 0.8565 - val_accuracy: 0.8800\n","Epoch 114/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4948 - accuracy: 0.9955 - val_loss: 0.7648 - val_accuracy: 0.9060\n","Epoch 115/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4824 - accuracy: 0.9972 - val_loss: 0.8486 - val_accuracy: 0.8920\n","Epoch 116/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4923 - accuracy: 0.9961 - val_loss: 0.7620 - val_accuracy: 0.8970\n","Epoch 117/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4901 - accuracy: 0.9960 - val_loss: 0.8827 - val_accuracy: 0.8880\n","Epoch 118/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4908 - accuracy: 0.9961 - val_loss: 0.7614 - val_accuracy: 0.9000\n","Epoch 119/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4990 - accuracy: 0.9943 - val_loss: 0.8256 - val_accuracy: 0.8940\n","Epoch 120/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4840 - accuracy: 0.9966 - val_loss: 0.8095 - val_accuracy: 0.8950\n","Epoch 121/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4958 - accuracy: 0.9959 - val_loss: 0.8176 - val_accuracy: 0.8940\n","Epoch 122/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4916 - accuracy: 0.9953 - val_loss: 0.7717 - val_accuracy: 0.8990\n","Epoch 123/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4931 - accuracy: 0.9944 - val_loss: 0.7529 - val_accuracy: 0.9050\n","Epoch 124/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4881 - accuracy: 0.9954 - val_loss: 0.8320 - val_accuracy: 0.8910\n","Epoch 125/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4950 - accuracy: 0.9946 - val_loss: 0.7807 - val_accuracy: 0.9010\n","Epoch 126/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.5002 - accuracy: 0.9950 - val_loss: 0.7956 - val_accuracy: 0.8890\n","Epoch 127/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4888 - accuracy: 0.9956 - val_loss: 0.7763 - val_accuracy: 0.8920\n","Epoch 128/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4871 - accuracy: 0.9955 - val_loss: 0.7649 - val_accuracy: 0.8990\n","Epoch 129/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4885 - accuracy: 0.9962 - val_loss: 0.8095 - val_accuracy: 0.8980\n","Epoch 130/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4881 - accuracy: 0.9952 - val_loss: 0.7547 - val_accuracy: 0.9050\n","Epoch 131/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4849 - accuracy: 0.9960 - val_loss: 0.7621 - val_accuracy: 0.9050\n","Epoch 132/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4942 - accuracy: 0.9948 - val_loss: 0.8309 - val_accuracy: 0.8930\n","Epoch 133/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4835 - accuracy: 0.9960 - val_loss: 0.7786 - val_accuracy: 0.8970\n","Epoch 134/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4860 - accuracy: 0.9961 - val_loss: 0.7852 - val_accuracy: 0.8930\n","Epoch 135/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4769 - accuracy: 0.9955 - val_loss: 0.8481 - val_accuracy: 0.8960\n","Epoch 136/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4774 - accuracy: 0.9965 - val_loss: 0.8540 - val_accuracy: 0.8910\n","Epoch 137/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4817 - accuracy: 0.9961 - val_loss: 0.8462 - val_accuracy: 0.8950\n","Epoch 138/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4820 - accuracy: 0.9954 - val_loss: 0.7927 - val_accuracy: 0.8990\n","Epoch 139/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4770 - accuracy: 0.9954 - val_loss: 0.8124 - val_accuracy: 0.8960\n","Epoch 140/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4757 - accuracy: 0.9965 - val_loss: 0.7845 - val_accuracy: 0.9010\n","Epoch 141/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4731 - accuracy: 0.9949 - val_loss: 0.7949 - val_accuracy: 0.9000\n","Epoch 142/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4770 - accuracy: 0.9961 - val_loss: 0.8496 - val_accuracy: 0.8860\n","Epoch 143/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4881 - accuracy: 0.9955 - val_loss: 0.7829 - val_accuracy: 0.9010\n","Epoch 144/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4815 - accuracy: 0.9959 - val_loss: 0.7954 - val_accuracy: 0.9000\n","Epoch 145/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4776 - accuracy: 0.9956 - val_loss: 0.7890 - val_accuracy: 0.8990\n","Epoch 146/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4845 - accuracy: 0.9954 - val_loss: 0.8008 - val_accuracy: 0.9030\n","Epoch 147/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4863 - accuracy: 0.9964 - val_loss: 0.8037 - val_accuracy: 0.8940\n","Epoch 148/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4949 - accuracy: 0.9954 - val_loss: 0.7613 - val_accuracy: 0.8950\n","Epoch 149/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4835 - accuracy: 0.9958 - val_loss: 0.8089 - val_accuracy: 0.8940\n","Epoch 150/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4723 - accuracy: 0.9965 - val_loss: 0.7774 - val_accuracy: 0.8980\n","Epoch 151/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4886 - accuracy: 0.9947 - val_loss: 0.7952 - val_accuracy: 0.8910\n","Epoch 152/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4765 - accuracy: 0.9964 - val_loss: 0.8018 - val_accuracy: 0.8930\n","Epoch 153/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4709 - accuracy: 0.9962 - val_loss: 0.7853 - val_accuracy: 0.9040\n","Epoch 154/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4692 - accuracy: 0.9971 - val_loss: 0.7703 - val_accuracy: 0.8980\n","Epoch 155/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4705 - accuracy: 0.9967 - val_loss: 0.8038 - val_accuracy: 0.8950\n","Epoch 156/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4689 - accuracy: 0.9962 - val_loss: 0.7878 - val_accuracy: 0.9060\n","Epoch 157/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4573 - accuracy: 0.9971 - val_loss: 0.7555 - val_accuracy: 0.9020\n","Epoch 158/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4759 - accuracy: 0.9950 - val_loss: 0.8138 - val_accuracy: 0.8840\n","Epoch 159/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4780 - accuracy: 0.9960 - val_loss: 0.8112 - val_accuracy: 0.8940\n","Epoch 160/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4756 - accuracy: 0.9970 - val_loss: 0.7822 - val_accuracy: 0.9040\n","Epoch 161/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4588 - accuracy: 0.9971 - val_loss: 0.8133 - val_accuracy: 0.8960\n","Epoch 162/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4855 - accuracy: 0.9947 - val_loss: 0.7294 - val_accuracy: 0.9060\n","Epoch 163/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4802 - accuracy: 0.9970 - val_loss: 0.7571 - val_accuracy: 0.9080\n","Epoch 164/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4736 - accuracy: 0.9946 - val_loss: 0.7343 - val_accuracy: 0.9020\n","Epoch 165/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4686 - accuracy: 0.9964 - val_loss: 0.7426 - val_accuracy: 0.9050\n","Epoch 166/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4844 - accuracy: 0.9965 - val_loss: 0.8424 - val_accuracy: 0.9000\n","Epoch 167/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4710 - accuracy: 0.9961 - val_loss: 0.7713 - val_accuracy: 0.8960\n","Epoch 168/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4819 - accuracy: 0.9946 - val_loss: 0.7896 - val_accuracy: 0.8960\n","Epoch 169/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4671 - accuracy: 0.9956 - val_loss: 0.7518 - val_accuracy: 0.9090\n","Epoch 170/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4580 - accuracy: 0.9962 - val_loss: 0.8281 - val_accuracy: 0.8910\n","Epoch 171/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4561 - accuracy: 0.9964 - val_loss: 0.8258 - val_accuracy: 0.8960\n","Epoch 172/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4599 - accuracy: 0.9971 - val_loss: 0.8185 - val_accuracy: 0.8930\n","Epoch 173/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4596 - accuracy: 0.9964 - val_loss: 0.9113 - val_accuracy: 0.8680\n","Epoch 174/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4663 - accuracy: 0.9965 - val_loss: 0.7655 - val_accuracy: 0.9040\n","Epoch 175/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4736 - accuracy: 0.9960 - val_loss: 0.7396 - val_accuracy: 0.9020\n","Epoch 176/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4737 - accuracy: 0.9973 - val_loss: 0.7918 - val_accuracy: 0.8960\n","Epoch 177/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4759 - accuracy: 0.9961 - val_loss: 0.7742 - val_accuracy: 0.8960\n","Epoch 178/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4673 - accuracy: 0.9964 - val_loss: 0.7537 - val_accuracy: 0.9040\n","Epoch 179/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4706 - accuracy: 0.9966 - val_loss: 0.7836 - val_accuracy: 0.8930\n","Epoch 180/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4737 - accuracy: 0.9958 - val_loss: 0.7949 - val_accuracy: 0.9020\n","Epoch 181/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4567 - accuracy: 0.9978 - val_loss: 0.8076 - val_accuracy: 0.8960\n","Epoch 182/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4671 - accuracy: 0.9956 - val_loss: 0.7737 - val_accuracy: 0.8950\n","Epoch 183/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4591 - accuracy: 0.9969 - val_loss: 0.7848 - val_accuracy: 0.9020\n","Epoch 184/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4523 - accuracy: 0.9968 - val_loss: 0.8043 - val_accuracy: 0.9050\n","Epoch 185/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4534 - accuracy: 0.9969 - val_loss: 0.7732 - val_accuracy: 0.9030\n","Epoch 186/300\n","372/372 [==============================] - 7s 18ms/step - loss: 0.4456 - accuracy: 0.9979 - val_loss: 0.7626 - val_accuracy: 0.9070\n","Epoch 187/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4441 - accuracy: 0.9976 - val_loss: 0.7497 - val_accuracy: 0.9080\n","Epoch 188/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4647 - accuracy: 0.9955 - val_loss: 0.7681 - val_accuracy: 0.9010\n","Epoch 189/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4678 - accuracy: 0.9950 - val_loss: 1.0652 - val_accuracy: 0.8460\n","Epoch 190/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4521 - accuracy: 0.9971 - val_loss: 0.8062 - val_accuracy: 0.8940\n","Epoch 191/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4732 - accuracy: 0.9958 - val_loss: 0.7733 - val_accuracy: 0.8950\n","Epoch 192/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4651 - accuracy: 0.9968 - val_loss: 0.7885 - val_accuracy: 0.8920\n","Epoch 193/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4577 - accuracy: 0.9960 - val_loss: 0.7928 - val_accuracy: 0.8970\n","Epoch 194/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4607 - accuracy: 0.9959 - val_loss: 0.8638 - val_accuracy: 0.8860\n","Epoch 195/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4532 - accuracy: 0.9962 - val_loss: 0.7757 - val_accuracy: 0.9010\n","Epoch 196/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4529 - accuracy: 0.9967 - val_loss: 0.7580 - val_accuracy: 0.9020\n","Epoch 197/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4575 - accuracy: 0.9964 - val_loss: 0.7885 - val_accuracy: 0.8920\n","Epoch 198/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4571 - accuracy: 0.9963 - val_loss: 0.8108 - val_accuracy: 0.8820\n","Epoch 199/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4436 - accuracy: 0.9971 - val_loss: 0.7778 - val_accuracy: 0.9040\n","Epoch 200/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4741 - accuracy: 0.9944 - val_loss: 0.7383 - val_accuracy: 0.8980\n","Epoch 201/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4623 - accuracy: 0.9972 - val_loss: 0.8089 - val_accuracy: 0.8980\n","Epoch 202/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4603 - accuracy: 0.9980 - val_loss: 0.7758 - val_accuracy: 0.8980\n","Epoch 203/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4528 - accuracy: 0.9978 - val_loss: 0.8815 - val_accuracy: 0.8820\n","Epoch 204/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4496 - accuracy: 0.9983 - val_loss: 0.8231 - val_accuracy: 0.8940\n","Epoch 205/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4609 - accuracy: 0.9961 - val_loss: 0.7726 - val_accuracy: 0.9010\n","Epoch 206/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4468 - accuracy: 0.9972 - val_loss: 0.7589 - val_accuracy: 0.8980\n","Epoch 207/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4670 - accuracy: 0.9965 - val_loss: 0.7699 - val_accuracy: 0.9010\n","Epoch 208/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4558 - accuracy: 0.9976 - val_loss: 0.8039 - val_accuracy: 0.8930\n","Epoch 209/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4657 - accuracy: 0.9955 - val_loss: 0.7640 - val_accuracy: 0.8960\n","Epoch 210/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4544 - accuracy: 0.9978 - val_loss: 0.7935 - val_accuracy: 0.9010\n","Epoch 211/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4602 - accuracy: 0.9961 - val_loss: 0.7545 - val_accuracy: 0.9020\n","Epoch 212/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4559 - accuracy: 0.9971 - val_loss: 0.8114 - val_accuracy: 0.8930\n","Epoch 213/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4611 - accuracy: 0.9974 - val_loss: 0.7819 - val_accuracy: 0.9020\n","Epoch 214/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4462 - accuracy: 0.9980 - val_loss: 0.9043 - val_accuracy: 0.8860\n","Epoch 215/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4692 - accuracy: 0.9973 - val_loss: 0.8151 - val_accuracy: 0.8850\n","Epoch 216/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4716 - accuracy: 0.9969 - val_loss: 0.7749 - val_accuracy: 0.8970\n","Epoch 217/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4529 - accuracy: 0.9976 - val_loss: 0.9169 - val_accuracy: 0.8840\n","Epoch 218/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4671 - accuracy: 0.9970 - val_loss: 0.7685 - val_accuracy: 0.8980\n","Epoch 219/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4644 - accuracy: 0.9979 - val_loss: 0.8178 - val_accuracy: 0.8930\n","Epoch 220/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4564 - accuracy: 0.9966 - val_loss: 0.8845 - val_accuracy: 0.8830\n","Epoch 221/300\n","372/372 [==============================] - 7s 17ms/step - loss: 0.4663 - accuracy: 0.9950 - val_loss: 0.8084 - val_accuracy: 0.8980\n","Epoch 222/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4688 - accuracy: 0.9972 - val_loss: 0.9986 - val_accuracy: 0.8340\n","Epoch 223/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4550 - accuracy: 0.9975 - val_loss: 0.7732 - val_accuracy: 0.9050\n","Epoch 224/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4445 - accuracy: 0.9977 - val_loss: 0.8144 - val_accuracy: 0.8900\n","Epoch 225/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4402 - accuracy: 0.9973 - val_loss: 0.8060 - val_accuracy: 0.9070\n","Epoch 226/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4484 - accuracy: 0.9966 - val_loss: 0.7605 - val_accuracy: 0.9000\n","Epoch 227/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4429 - accuracy: 0.9973 - val_loss: 0.7829 - val_accuracy: 0.9020\n","Epoch 228/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4450 - accuracy: 0.9978 - val_loss: 0.8215 - val_accuracy: 0.8940\n","Epoch 229/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4541 - accuracy: 0.9977 - val_loss: 0.7478 - val_accuracy: 0.8980\n","Epoch 230/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4749 - accuracy: 0.9948 - val_loss: 1.1419 - val_accuracy: 0.8090\n","Epoch 231/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.5032 - accuracy: 0.9954 - val_loss: 0.7484 - val_accuracy: 0.8990\n","Epoch 232/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4652 - accuracy: 0.9977 - val_loss: 0.7694 - val_accuracy: 0.8980\n","Epoch 233/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4630 - accuracy: 0.9956 - val_loss: 1.2849 - val_accuracy: 0.7920\n","Epoch 234/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4519 - accuracy: 0.9966 - val_loss: 0.7893 - val_accuracy: 0.9090\n","Epoch 235/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4438 - accuracy: 0.9971 - val_loss: 0.7818 - val_accuracy: 0.8970\n","Epoch 236/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4404 - accuracy: 0.9978 - val_loss: 0.8082 - val_accuracy: 0.8980\n","Epoch 237/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4501 - accuracy: 0.9972 - val_loss: 0.7935 - val_accuracy: 0.8920\n","Epoch 238/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4412 - accuracy: 0.9971 - val_loss: 0.7817 - val_accuracy: 0.8960\n","Epoch 239/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4500 - accuracy: 0.9962 - val_loss: 0.8352 - val_accuracy: 0.8940\n","Epoch 240/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4421 - accuracy: 0.9974 - val_loss: 0.7710 - val_accuracy: 0.9020\n","Epoch 241/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4290 - accuracy: 0.9987 - val_loss: 0.7945 - val_accuracy: 0.8900\n","Epoch 242/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4438 - accuracy: 0.9975 - val_loss: 0.7845 - val_accuracy: 0.9010\n","Epoch 243/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4412 - accuracy: 0.9976 - val_loss: 0.7542 - val_accuracy: 0.9050\n","Epoch 244/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4620 - accuracy: 0.9975 - val_loss: 0.8252 - val_accuracy: 0.8870\n","Epoch 245/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4528 - accuracy: 0.9982 - val_loss: 1.1300 - val_accuracy: 0.7810\n","Epoch 246/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4647 - accuracy: 0.9966 - val_loss: 0.8202 - val_accuracy: 0.8990\n","Epoch 247/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4697 - accuracy: 0.9966 - val_loss: 0.7823 - val_accuracy: 0.9040\n","Epoch 248/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4562 - accuracy: 0.9972 - val_loss: 0.8858 - val_accuracy: 0.8840\n","Epoch 249/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4492 - accuracy: 0.9968 - val_loss: 0.7851 - val_accuracy: 0.8950\n","Epoch 250/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4453 - accuracy: 0.9977 - val_loss: 0.8122 - val_accuracy: 0.8940\n","Epoch 251/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4439 - accuracy: 0.9969 - val_loss: 0.8148 - val_accuracy: 0.8940\n","Epoch 252/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4442 - accuracy: 0.9970 - val_loss: 0.8306 - val_accuracy: 0.8920\n","Epoch 253/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4428 - accuracy: 0.9982 - val_loss: 0.8074 - val_accuracy: 0.8900\n","Epoch 254/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4425 - accuracy: 0.9980 - val_loss: 0.7895 - val_accuracy: 0.8970\n","Epoch 255/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4358 - accuracy: 0.9984 - val_loss: 0.8127 - val_accuracy: 0.9020\n","Epoch 256/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4558 - accuracy: 0.9962 - val_loss: 0.8142 - val_accuracy: 0.8940\n","Epoch 257/300\n","372/372 [==============================] - 7s 18ms/step - loss: 0.4577 - accuracy: 0.9975 - val_loss: 1.0280 - val_accuracy: 0.8570\n","Epoch 258/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4325 - accuracy: 0.9979 - val_loss: 0.8543 - val_accuracy: 0.8890\n","Epoch 259/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4791 - accuracy: 0.9961 - val_loss: 0.7953 - val_accuracy: 0.8910\n","Epoch 260/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4483 - accuracy: 0.9980 - val_loss: 0.7969 - val_accuracy: 0.8990\n","Epoch 261/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4483 - accuracy: 0.9968 - val_loss: 0.8149 - val_accuracy: 0.9020\n","Epoch 262/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4414 - accuracy: 0.9977 - val_loss: 0.7840 - val_accuracy: 0.8970\n","Epoch 263/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4515 - accuracy: 0.9969 - val_loss: 0.7529 - val_accuracy: 0.9050\n","Epoch 264/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4444 - accuracy: 0.9965 - val_loss: 0.8522 - val_accuracy: 0.8970\n","Epoch 265/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4302 - accuracy: 0.9983 - val_loss: 0.9156 - val_accuracy: 0.8810\n","Epoch 266/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4344 - accuracy: 0.9981 - val_loss: 0.9051 - val_accuracy: 0.8880\n","Epoch 267/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4402 - accuracy: 0.9966 - val_loss: 0.8208 - val_accuracy: 0.8900\n","Epoch 268/300\n","372/372 [==============================] - 6s 17ms/step - loss: 0.4372 - accuracy: 0.9974 - val_loss: 0.7770 - val_accuracy: 0.9040\n","Epoch 269/300\n","372/372 [==============================] - 6s 16ms/step - loss: 0.4380 - accuracy: 0.9978 - val_loss: 0.7949 - val_accuracy: 0.8940\n","Temps total : 1645.8929603099823ms\n","322/322 [==============================] - 5s 15ms/step - loss: 0.7301 - accuracy: 0.9088\n","[0.7301310300827026, 0.9088172316551208]\n"]}],"source":["filepath =\"oad.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n","callbacks = [checkpoint,EarlyStopping(monitor='val_accuracy', patience=100,)]\n","debut = time.time()\n","history=model.fit(train[0], train[1],\n","              epochs=300,\n","              batch_size=batch_size,\n","              validation_data=(val_x,val_y),\n","              callbacks=callbacks,\n","              verbose=1)\n","fin = time.time()\n","print(\"Temps total : \" + str(fin - debut) + \"ms\")\n","model = keras.models.load_model('oad.hdf5')\n","keras.models.save_model(model, base_path+'_perso_64.h5')\n","print(model.evaluate(test[0],test[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OlGLtIKFV0bK"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"Perso.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}