{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30853,"status":"ok","timestamp":1646055401938,"user":{"displayName":"Fer Vincent","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04845778604314705618"},"user_tz":-60},"id":"1rGrp3gMySS6","outputId":"5112d09e-01a4-4640-fa5a-afbc4b82c2ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":701772,"status":"ok","timestamp":1646056435595,"user":{"displayName":"Fer Vincent","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04845778604314705618"},"user_tz":-60},"id":"I7rd_PSTx0qm","outputId":"d357821f-49f1-40e5-9089-3eab65f4b9bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["rm: cannot remove '/content/ntu_encoder.zip': No such file or directory\n"]}],"source":["#!cp \"/content/drive/MyDrive/Colab Notebooks/ntu_encoder_no_order.zip\" \"/content/\"\n","#!ls -l \"/content/\"\n","import zipfile\n","zip_ref = zipfile.ZipFile(\"/content/ntu_encoder_no_order.zip\", 'r')\n","zip_ref.extractall(\"/\")\n","zip_ref.close()\n","!rm \"/content/ntu_encoder_no_order.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFGDbdNObQay"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from matplotlib import pyplot\n","import numpy as np\n","import sys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OKLk2ihec6xb"},"outputs":[],"source":["def def_model():\n","  model = tf.keras.models.Sequential()\n","  model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","  model.add(Conv2D(filters=128,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(Conv2D(filters=128,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","  model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n","  model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n","  model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n","  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n","  model.add(Flatten())\n","  model.add(Dense(units=4096,activation=\"relu\"))\n","  model.add(Dense(units=4096,activation=\"relu\"))\n","  model.add(Dense(units=120,activation=\"softmax\"))\n","  opt = tf.optimizers.Adam(learning_rate=0.001)\n","  model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQjpxE0e2DIj"},"outputs":[],"source":["# plot diagnostic learning curves\n","def summarize_diagnostics(history):\n","\t# plot loss\n","\tpyplot.subplot(211)\n","\tpyplot.title('Cross Entropy Loss')\n","\tpyplot.plot(history.history['loss'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n","\t# plot accuracy\n","\tpyplot.subplot(212)\n","\tpyplot.title('Classification Accuracy')\n","\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n","\t# save plot to file\n","\tfilename = sys.argv[0].split('/')[-1]\n","\tpyplot.savefig(\"/content/drive/MyDrive/Colab Notebooks/vgg16/\" + filename + '_plot.png')\n","\tpyplot.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GfJ8icX-yz9l"},"outputs":[],"source":["# run the test harness for evaluating a model\n","def evaluationModele():\n","  # définition du modèle\n","  model = def_model()\n","  ###\n","  train_batch_size=140\n","  test_batch_size=14\n","  train_datagen = ImageDataGenerator()\n","  test_datagen = ImageDataGenerator()\n","  # l'iterateur dans le dossier d'entrainement, génère des lots d'image augmentées et normalisées, le batch size est à 16 car on a assez peu d'images\n","  train_it = train_datagen.flow_from_directory('/content/ntu_encoder/train/',\n","    class_mode='categorical', batch_size=train_batch_size, target_size=(224, 224))\n","  # récupération des indices pour avoir une visualisation de comment est rangé le tout\n","  label_map = (train_it.class_indices)\n","  print(label_map)\n","  test_it = test_datagen.flow_from_directory('/content/ntu_encoder/test/',\n","    class_mode='categorical', batch_size=test_batch_size, target_size=(224, 224))\n","  # entrainement du modèle\n","  #checkpoint = ModelCheckpoint(\"/content/vgg16_1.h5\", monitor=\"val_accuracy\", verbose=0,save_best_only=True,save_weights_only=False,mode='auto',save_freq=1)\n","  #early = EarlyStopping(monitor='val_accuracy',min_delta=0,patience=20,verbose=0,mode='auto')\n","  hist=model.fit_generator(generator=train_it,steps_per_epoch=train_it.samples/train_it.batch_size,validation_data=test_it,validation_steps=test_it.samples/test_it.batch_size,epochs=5,verbose=1)\n","  # evaluation du modèle\n","  _, acc = model.evaluate(test_it, steps=len(test_it), verbose=1)\n","  print('> %.3f' % (acc * 100.0))\n","  # learning curves\n","  summarize_diagnostics(hist)\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"PH7b77Pp5Dea","outputId":"9ed2d5e3-f16a-4201-a24f-724febca7160"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 4848172 images belonging to 120 classes.\n","{'apply cream on face': 0, 'apply cream on hand': 1, 'arm circles': 2, 'arm swings': 3, 'back pain': 4, 'blow nose': 5, 'bouce ball': 6, 'brush hair': 7, 'brush teeth': 8, 'bull up paper': 9, 'butt kicks': 10, 'capitulate': 11, 'carry object': 12, 'check time': 13, 'cheer up': 14, 'cheers and drink': 15, 'chest pain': 16, 'clapping': 17, 'couting money': 18, 'cross arms': 19, 'cross hands in front': 20, 'cross toe touch': 21, 'cutting nails': 22, 'cutting paper': 23, 'drink water': 24, 'drop': 25, 'eat meal': 26, 'exchange things': 27, 'falling down': 28, 'fan self': 29, 'flick hair': 30, 'fold paper': 31, 'follow': 32, 'giving object': 33, 'grab stuff': 34, 'hand waving': 35, 'headache': 36, 'high-five': 37, 'hit with object': 38, 'hopping': 39, 'hugging': 40, 'hush': 41, 'juggle bat tennis ball': 42, 'jump up': 43, 'kicking': 44, 'kicking something': 45, 'knock over': 46, 'make OK sign': 47, 'make victory sign': 48, 'move heavy objects': 49, 'nausea vomiting': 50, 'neck pain': 51, 'nod head bow': 52, 'open a box': 53, 'open bottle': 54, 'pat on back': 55, 'phone call': 56, 'pick up': 57, 'play magic cube': 58, 'play with phone  tablet': 59, 'point finger': 60, 'point to something': 61, 'punch slap': 62, 'pushing': 63, 'put object into bag': 64, 'put on a hat cap': 65, 'put on a shoe': 66, 'put on bag': 67, 'put on glasses': 68, 'put on headphone': 69, 'put on jacket': 70, 'put palms together': 71, 'reach into pocket': 72, 'reading': 73, 'rock-paper-scissors': 74, 'rub two hands': 75, 'run on the spots': 76, 'salute': 77, 'shake fist': 78, 'shake head': 79, 'shaking hands': 80, 'shoot at basket': 81, 'shoot with gun': 82, 'side kick': 83, 'sit down': 84, 'snap fingers': 85, 'sneeze cough': 86, 'sniff smell': 87, 'squat down': 88, 'staggering': 89, 'stand up': 90, 'staple book': 91, 'step on foot': 92, 'stretch one self': 93, 'support somebody': 94, 'take a photo': 95, 'take object out of bag': 96, 'take off a hat cap': 97, 'take off a shoe': 98, 'take off bag': 99, 'take off glasses': 100, 'take off headphone': 101, 'take off jacket': 102, 'taking a selfie': 103, 'tear up paper': 104, 'tennis bat swing': 105, 'throw': 106, 'throw up cap hat': 107, 'thumb down': 108, 'thumb up': 109, 'toss a coin': 110, 'touch pocket': 111, 'type on a keyboard': 112, 'walking apart': 113, 'walking towards': 114, 'whisper': 115, 'wield knife': 116, 'wipe face': 117, 'writing': 118, 'yawn': 119}\n","Found 537432 images belonging to 120 classes.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","34629/34629 [==============================] - 21267s 614ms/step - loss: 1.3418 - accuracy: 0.6244 - val_loss: 0.7403 - val_accuracy: 0.7688\n","Epoch 2/5\n"," 6533/34629 [====>.........................] - ETA: 4:32:13 - loss: 0.6536 - accuracy: 0.7933"]}],"source":["model = evaluationModele()\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/vgg16/modelNtu120_entier.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QwKS97Kw4Vu-"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"vgg16_train_gpu.ipynb","provenance":[],"authorship_tag":"ABX9TyNKRIaVOZAjyB1bvVwJHc3D"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}